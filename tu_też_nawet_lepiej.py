# -*- coding: utf-8 -*-
"""Tu też - nawet lepiej.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12-TQttxjdIA02SdNZTuSLx7Jnyrpf_3k

# Setup Data

Mount GDrive
"""

from google.colab import drive
drive.mount('/content/drive',  force_remount=True)

"""Set paths"""

dataset_dir = "drive/MyDrive/dataset/"

"""### UC Land Use Dataset"""

UC_land_use_dir = dataset_dir + "UCMerced_LandUse/Images"
UC_land_use_classes = ['airplane',
 'chaparral',
 'forest',
 'buildings',
 'agricultural',
 'baseballdiamond',
 'denseresidential',
 'beach',
 'freeway',
 'parkinglot',
 'harbor',
 'golfcourse',
 'intersection',
 'overpass',
 'mobilehomepark',
 'mediumresidential',
 'river',
 'runway',
 'storagetanks',
 'sparseresidential',
 'tenniscourt']
UC_land_use_classes.sort()
UC_land_use_image_size = 255
UC_land_use_class_num = len(UC_land_use_classes)

# Commented out IPython magic to ensure Python compatibility.
import os
import numpy as np
import torch

import torchvision
from torchvision import datasets, models, transforms
import matplotlib.pyplot as plt

# %matplotlib inline

"""## CUDA check"""

# check if CUDA is available
train_on_gpu = torch.cuda.is_available()

if not train_on_gpu:
    print('❌CUDA is not available.  Training on CPU ...')
else:
    print('✅CUDA is available!  Training on GPU ...')

"""## Choose dataset"""

# specify the image classes
classes = UC_land_use_classes
image_size = UC_land_use_image_size
print(len(classes))

from termcolor import colored

"""## Load and Transform Data"""

from torchvision import datasets
import torchvision.transforms as transforms
from torch.utils.data.sampler import SubsetRandomSampler

# number of subprocesses to use for data loading
num_workers = 0
# how many samples per batch to load
batch_size = 20
# percentage of training set to use as validation
train_portion = 0.7
validation_portion = 0.2
test_portion = 0.1
if round(train_portion + validation_portion + test_portion) != 1:
    print(colored('❌Wrong sizes', 'red'))
else:
    print(colored('✅Sizes match', 'green'))

# convert data to a normalized torch.FloatTensor
transform = transforms.Compose([transforms.RandomRotation(30),
                                       transforms.Resize((image_size, image_size)),
                                       transforms.RandomHorizontalFlip(),
                                       transforms.RandomRotation(360),
                                       transforms.ToTensor(),
                                       transforms.Normalize([0.485, 0.456, 0.406],
                                                            [0.229, 0.224, 0.225])])

# choose the training and test datasets
dataset = datasets.ImageFolder(UC_land_use_dir, transform=transform)



train_length = int(len(dataset.imgs)*train_portion)
validation_length = int(len(dataset.imgs)*validation_portion)
test_length = int(len(dataset.imgs)*test_portion)

# check sets lengsths
print(f'dataset length:     {len(dataset.imgs)}')
print(f'train_length:       {train_length}')
print(f'validation_length:  {validation_length}')
print(f'test_length:        {test_length}')
if test_length + train_length + validation_length == len(dataset.imgs):
    print('✅ lengths correct')
else:
    print('❌ lengths incorrect')


# split and load data
train_set, validation_set, test_set = torch.utils.data.random_split(dataset, [train_length, validation_length, test_length])

train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, num_workers=num_workers)
validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=batch_size, num_workers=num_workers)
test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, num_workers=num_workers)

print('Train loader:    ', len(train_loader))
print('Valid loader:    ', len(validation_loader))
print('Test loader:     ', len(test_loader))

len(dataset)

"""### DataLoaders and Data Visualization"""

# Visualize some sample data

# obtain one batch of training images
dataiter = iter(train_loader)
images, labels = dataiter.next()
images = images.numpy() # convert images to numpy for display

# plot the images in the batch, along with the corresponding labels
fig = plt.figure(figsize=(25, 4))
for idx in np.arange(20):
    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])
    plt.imshow(np.transpose(images[idx], (1, 2, 0)))
    ax.set_title(classes[labels[idx]])

"""---
## Define the Model

To define a model for training we'll follow these steps:
1. Load in a pre-trained VGG16 model
2. "Freeze" all the parameters, so the net acts as a fixed feature extractor 
3. Remove the last layer
4. Replace the last layer with a linear classifier of our own

**Freezing simply means that the parameters in the pre-trained model will *not* change during training.**

Pick existing model
"""

import torchvision.models as models

# model = models.resnet18(pretrained=True)
# model = models.alexnet(pretrained=True)
# model = models.squeezenet1_0(pretrained=True)
model = models.vgg16(pretrained=True)
# model = models.densenet161(pretrained=True)
# model = models.inception_v3(pretrained=True)
# model = models.googlenet(pretrained=True)
# model = models.shufflenet_v2_x1_0(pretrained=True)
# model = models.mobilenet_v2(pretrained=True)
# model = models.mobilenet_v3_large(pretrained=True)
# model = models.mobilenet_v3_small(pretrained=True)
# model = models.resnext50_32x4d(pretrained=True)
# model = models.wide_resnet50_2(pretrained=True)
# model = models.mnasnet1_0(pretrained=True)


# print out the model structure
print(model)
print(model.classifier[6].in_features) 
print(model.classifier[6].out_features)
# Freeze training for all "features" layers
for param in model.features.parameters():
    param.requires_grad = False

"""---
### Final Classifier Layer

Once you have the pre-trained feature extractor, you just need to modify and/or add to the final, fully-connected classifier layers. In this case, we suggest that you repace the last layer in the vgg classifier group of layers. 
> This layer should see as input the number of features produced by the portion of the network that you are not changing, and produce an appropriate number of outputs for the flower classification task.

You can access any layer in a pretrained network by name and (sometimes) number, i.e. `vgg16.classifier[6]` is the sixth layer in a group of layers named "classifier".
"""

import torch.nn as nn

n_inputs = model.classifier[6].in_features

# add last linear layer (n_inputs -> 5 flower classes)
# new layers automatically have requires_grad = True
last_layer = nn.Linear(n_inputs, len(classes))

model.classifier[6] = last_layer

# if GPU is available, move the model to GPU
if train_on_gpu:
    model.cuda()

# check to see that your last layer produces the expected number of outputs
print(model.classifier[6].out_features)
#print(model)

"""### Specify [Loss Function](http://pytorch.org/docs/stable/nn.html#loss-functions) and [Optimizer](http://pytorch.org/docs/stable/optim.html)

Below we'll use cross-entropy loss and stochastic gradient descent with a small learning rate. Note that the optimizer accepts as input _only_ the trainable parameters `vgg.classifier.parameters()`.
"""

import torch.optim as optim

# specify loss function (categorical cross-entropy)
criterion = nn.CrossEntropyLoss()

# specify optimizer (stochastic gradient descent) and learning rate = 0.001
optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)

"""---
## Training

Here, we'll train the network.

> **Exercise:** So far we've been providing the training code for you. Here, I'm going to give you a bit more of a challenge and have you write the code to train the network. Of course, you'll be able to see my solution if you need help.
"""

# number of epochs to train the model
n_epochs = 1000
no_improvement = 0
max_no_improve_epochs = 20
valid_loss_min = np.Inf

train_loss_array=[]
valid_loss_array=[]

for epoch in range(1, n_epochs+1):

    # early stopping
    if no_improvement >=  max_no_improve_epochs:
        break

    # keep track of training and validation loss
    train_loss = 0.0
    train_loss_tmp = 0.0
    valid_loss = 0.0
    
    ###################
    # train the model #
    ###################
    model.train()
    # model by default is set to train
    for batch_i, (data, target) in enumerate(train_loader):
        # move tensors to GPU if CUDA is available
        if train_on_gpu:
            data, target = data.cuda(), target.cuda()
        # clear the gradients of all optimized variables
        optimizer.zero_grad()
        # forward pass: compute predicted outputs by passing inputs to the model
        output = model(data)
        # calculate the batch loss
        loss = criterion(output, target)
        # backward pass: compute gradient of the loss with respect to model parameters
        loss.backward()
        # perform a single optimization step (parameter update)
        optimizer.step()
        # update training loss 
        train_loss_tmp += loss.item()
        train_loss += loss.item()*data.size(0)
        
        if batch_i % 20 == 19:    # print training loss every specified number of mini-batches
            print(f'Epoch {epoch}, Batch {batch_i + 1}/{batch_size} loss: {(train_loss_tmp / 20):.16f}')
            train_loss_tmp = 0.0
    ######################
    # evaluate the model #
    ######################
    model.eval()

    for batch_i, (data, target) in enumerate(validation_loader):

      # cuda
      if train_on_gpu:
        data, target = data.cuda(), target.cuda()

      y = model(data)
      loss = criterion(y, target)
      valid_loss += loss.item()*data.size(0)

    train_loss = train_loss/len(train_loader.sampler)
    valid_loss = valid_loss/len(validation_loader.sampler)

    # print training/validation statistics 
    print(f'Evaluation\nEpoch: {epoch + 1}/{n_epochs+1} \tTraining Loss: {train_loss:.6f} \tValidation Loss: {valid_loss:.6f}')
    train_loss_array.append(train_loss)
    valid_loss_array.append(valid_loss)
    # save model if validation loss has decreased
    if valid_loss <= valid_loss_min:
      print(f'⌛ Validation loss decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}).  Saving model ...')    
      torch.save(model.state_dict(), f'{epoch:03d}model_cifar.pt')
      valid_loss_min = valid_loss
      no_improvement = 0
    else:
      no_improvement += 1

min_idx = train_loss_array.index(min(train_loss_array))
plt.plot(train_loss_array[:min_idx])
plt.ylabel('Train loss')
plt.show()

min_idx = valid_loss_array.index(min(valid_loss_array))
plt.plot(valid_loss_array[:min_idx])
plt.ylabel('Valid loss')
plt.show()

"""---
## Testing

Below you see the test accuracy for each flower class.
"""

target.data

# track test loss 
# over 5 flower classes
test_loss = 0.0
class_correct = list(0. for i in range(len(classes)))
class_total = list(0. for i in range(len(classes)))

model.eval() # eval mode
if train_on_gpu:
    model.cuda()

# iterate over test data
for data, target in test_loader:

    if len(target.data) < batch_size:
        break;
    # move tensors to GPU if CUDA is available
    if train_on_gpu:
        data, target = data.cuda(), target.cuda()
    # forward pass: compute predicted outputs by passing inputs to the model
    output = model(data)
    # calculate the batch loss
    loss = criterion(output, target)
    # update  test loss 
    test_loss += loss.item()*data.size(0)
    # convert output probabilities to predicted class
    _, pred = torch.max(output, 1)    
    # compare predictions to true label
    correct_tensor = pred.eq(target.data.view_as(pred))
    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())
    # calculate test accuracy for each object class
    for i in range(batch_size):
        label = target.data[i]
        class_correct[label] += correct[i].item()
        class_total[label] += 1

# calculate avg test loss
test_loss = test_loss/len(test_loader.dataset)
print('Test Loss: {:.6f}\n'.format(test_loss))

for i in range(len(class_total)):
    if class_total[i] > 0:
        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (
            classes[i], 100 * class_correct[i] / class_total[i],
            np.sum(class_correct[i]), np.sum(class_total[i])))
    else:
        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))

print('\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (
    100. * np.sum(class_correct) / np.sum(class_total),
    np.sum(class_correct), np.sum(class_total)))

"""### Visualize Sample Test Results"""

# obtain one batch of test images
dataiter = iter(test_loader)
images, labels = dataiter.next()
images.numpy()

model.cpu()
# get sample outputs
output = model(images)
# convert output probabilities to predicted class
_, preds_tensor = torch.max(output, 1)
preds = np.squeeze(preds_tensor.cpu().numpy())

# plot the images in the batch, along with predicted and true labels
fig = plt.figure(figsize=(40, 5))
for idx in np.arange(batch_size):
    ax = fig.add_subplot(2, batch_size/2, idx+1, xticks=[], yticks=[])
    plt.imshow(np.transpose(images[idx], (1, 2, 0)))
    ax.set_title("{} ({})".format(classes[preds[idx]], classes[labels[idx]]),
                 color=("green" if preds[idx]==labels[idx].item() else "red"))